{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb5ef28-309c-4447-8dbc-bd5eb2300fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "!pip install ultralytics -q\n",
    "# !pip install gradio -q\n",
    "# !pip install pandas -q\n",
    "!pip install deepface -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67268226-bac1-464c-87e2-c5e1fda044e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.engine.results import Results  \n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "# import gradio as gr\n",
    "import shutil\n",
    "import pandas\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c62a9d-8112-49b7-9b8d-43f9e10673c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceRecognition(input_image):\n",
    "    # Path to the directory containing cropped objects\n",
    "    cropped_objects_dir = \"./faces/\"\n",
    "    \n",
    "    # Path to the directory to save unknown faces\n",
    "    unknown_faces_dir = \"./unknown/\"\n",
    "    \n",
    "    # Path to the directory to save known faces\n",
    "    known_faces_dir = \"./known/\"\n",
    "    \n",
    "    # Initialize a list to store the extracted names\n",
    "    extracted_names = []\n",
    "    \n",
    "    # Check if the 'unknown' folder exists, otherwise create it\n",
    "    if not os.path.exists(unknown_faces_dir):\n",
    "        os.makedirs(unknown_faces_dir)\n",
    "    else:\n",
    "        # If the 'unknown' folder exists, clear all files and subfolders\n",
    "        for file_or_folder in os.listdir(unknown_faces_dir):\n",
    "            file_or_folder_path = os.path.join(unknown_faces_dir, file_or_folder)\n",
    "            if os.path.isfile(file_or_folder_path):\n",
    "                os.remove(file_or_folder_path)\n",
    "            elif os.path.isdir(file_or_folder_path):\n",
    "                shutil.rmtree(file_or_folder_path)\n",
    "\n",
    "    # Check if the 'known' folder exists, otherwise create it\n",
    "    if not os.path.exists(known_faces_dir):\n",
    "        os.makedirs(known_faces_dir)\n",
    "    else:\n",
    "        # If the 'known' folder exists, clear all files and subfolders\n",
    "        for file_or_folder in os.listdir(known_faces_dir):\n",
    "            file_or_folder_path = os.path.join(known_faces_dir, file_or_folder)\n",
    "            if os.path.isfile(file_or_folder_path):\n",
    "                os.remove(file_or_folder_path)\n",
    "            elif os.path.isdir(file_or_folder_path):\n",
    "                shutil.rmtree(file_or_folder_path)\n",
    "\n",
    "    # Iterate through the image files in the directory\n",
    "    for filename in os.listdir(cropped_objects_dir):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(cropped_objects_dir, filename)\n",
    "            model = DeepFace.find(img_path=img_path, db_path=\"database\", enforce_detection=False, model_name=\"Facenet512\")\n",
    "\n",
    "            # Check if a face was recognized in the image\n",
    "            if model and len(model[0]['identity']) > 0:\n",
    "                # Extract the name and append it to the list\n",
    "                name = model[0]['identity'][0].split('/')[1]\n",
    "                \n",
    "                # Save the known face into the 'known' folder\n",
    "                known_faces_path = os.path.join(known_faces_dir, f\"{len(extracted_names) + 1}_{name}.jpg\")\n",
    "                shutil.copy(img_path, known_faces_path)\n",
    "                \n",
    "            else:\n",
    "                # If no face is recognized, set name to 'unknown'\n",
    "                name = 'unknown'\n",
    "                \n",
    "                # Save the unknown face into the 'unknown' folder\n",
    "                unknown_faces_path = os.path.join(unknown_faces_dir, f\"{len(extracted_names) + 1}.jpg\")\n",
    "                shutil.copy(img_path, unknown_faces_path)\n",
    "                \n",
    "            extracted_names.append(name)\n",
    "            \n",
    "    return extracted_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61dff16-32e7-42fc-b312-4d5cb175628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceExtraction(input_image, model, results):\n",
    "    # Load the image\n",
    "    image = Image.open(input_image)\n",
    "    detected_objects = []\n",
    "\n",
    "    if hasattr(results, 'boxes') and hasattr(results, 'names'):\n",
    "        for box in results.boxes.xyxy:\n",
    "            object_id = int(box[-1])\n",
    "            object_name = results.names.get(object_id)\n",
    "            x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "\n",
    "            detected_objects.append((object_name, (x1, y1, x2, y2)))\n",
    "\n",
    "    # Create or clear the 'faces' directory\n",
    "    if os.path.exists(\"faces\"):\n",
    "        shutil.rmtree(\"faces\")\n",
    "    os.makedirs(\"faces\")\n",
    "\n",
    "    # Crop and save each detected object\n",
    "    for i, (object_name, (x1, y1, x2, y2)) in enumerate(detected_objects):\n",
    "        object_image = image.crop((x1, y1, x2, y2))\n",
    "        object_image.save(f\"faces/face{i}.jpg\")\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b301be-5c7c-46d8-b23e-0c7686cf9e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceDetection(input_image):\n",
    "    model = YOLO('best.pt')\n",
    "    results: Results = model.predict(input_image)[0]\n",
    "\n",
    "    return faceExtraction(input_image, model, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e3b20-c871-4df7-a539-6248c405fc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/anirudh/Desktop/DS_environment/F_R/DSCN0797.JPG: 480x640 7 faces, 99.9ms\n",
      "Speed: 9.1ms preprocess, 99.9ms inference, 10.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "24-07-01 12:09:53 - Found 26 newly added image(s), 0 removed image(s), 0 replaced image(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding representations: 100%|██████████| 26/26 [02:00<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-07-01 12:11:54 - There are now 275 representations in ds_model_facenet512_detector_opencv_aligned_normalization_base_expand_0.pkl\n",
      "24-07-01 12:11:54 - Searching ./faces/face1.jpg in 275 length datastore\n",
      "24-07-01 12:11:54 - find function duration 120.68945622444153 seconds\n",
      "24-07-01 12:11:54 - Searching ./faces/face0.jpg in 275 length datastore\n",
      "24-07-01 12:11:54 - find function duration 0.2228379249572754 seconds\n",
      "24-07-01 12:11:54 - Searching ./faces/face2.jpg in 275 length datastore\n",
      "24-07-01 12:11:54 - find function duration 0.18482685089111328 seconds\n",
      "24-07-01 12:11:54 - Searching ./faces/face3.jpg in 275 length datastore\n",
      "24-07-01 12:11:55 - find function duration 0.17038536071777344 seconds\n",
      "24-07-01 12:11:55 - Searching ./faces/face6.jpg in 275 length datastore\n",
      "24-07-01 12:11:55 - find function duration 0.20537900924682617 seconds\n",
      "24-07-01 12:11:55 - Searching ./faces/face4.jpg in 275 length datastore\n",
      "24-07-01 12:11:55 - find function duration 0.21099328994750977 seconds\n",
      "24-07-01 12:11:55 - Searching ./faces/face5.jpg in 275 length datastore\n",
      "24-07-01 12:11:55 - find function duration 0.1966848373413086 seconds\n",
      "['Jai', 'Sumukh', 'Pranav', 'Akshara', 'Ojasva', 'Ansh', 'Deepak']\n"
     ]
    }
   ],
   "source": [
    "image = input(\"enter image path : \")\n",
    "faceDetection(image)\n",
    "names = faceRecognition(image)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.engine.results import Results  \n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def faceRecognition(input_image):\n",
    "    cropped_objects_dir = \"./faces/\"\n",
    "    unknown_faces_dir = \"./unknown/\"\n",
    "    known_faces_dir = \"./known/\"\n",
    "    extracted_names = []\n",
    "    \n",
    "    if not os.path.exists(unknown_faces_dir):\n",
    "        os.makedirs(unknown_faces_dir)\n",
    "    else:\n",
    "        for file_or_folder in os.listdir(unknown_faces_dir):\n",
    "            file_or_folder_path = os.path.join(unknown_faces_dir, file_or_folder)\n",
    "            if os.path.isfile(file_or_folder_path):\n",
    "                os.remove(file_or_folder_path)\n",
    "            elif os.path.isdir(file_or_folder_path):\n",
    "                shutil.rmtree(file_or_folder_path)\n",
    "\n",
    "    if not os.path.exists(known_faces_dir):\n",
    "        os.makedirs(known_faces_dir)\n",
    "    else:\n",
    "        for file_or_folder in os.listdir(known_faces_dir):\n",
    "            file_or_folder_path = os.path.join(known_faces_dir, file_or_folder)\n",
    "            if os.path.isfile(file_or_folder_path):\n",
    "                os.remove(file_or_folder_path)\n",
    "            elif os.path.isdir(file_or_folder_path):\n",
    "                shutil.rmtree(file_or_folder_path)\n",
    "\n",
    "    for filename in os.listdir(cropped_objects_dir):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(cropped_objects_dir, filename)\n",
    "            model = DeepFace.find(img_path=img_path, db_path=\"database\", enforce_detection=False, model_name=\"Facenet512\")\n",
    "\n",
    "            if model and len(model[0]['identity']) > 0:\n",
    "                name = model[0]['identity'][0].split('/')[1]\n",
    "                known_faces_path = os.path.join(known_faces_dir, f\"{len(extracted_names) + 1}_{name}.jpg\")\n",
    "                shutil.copy(img_path, known_faces_path)\n",
    "            else:\n",
    "                name = 'unknown'\n",
    "                unknown_faces_path = os.path.join(unknown_faces_dir, f\"{len(extracted_names) + 1}.jpg\")\n",
    "                shutil.copy(img_path, unknown_faces_path)\n",
    "                \n",
    "            extracted_names.append(name)\n",
    "            \n",
    "    return extracted_names\n",
    "\n",
    "def faceExtraction(input_image, model, results):\n",
    "    image = Image.open(input_image)\n",
    "    detected_objects = []\n",
    "\n",
    "    if hasattr(results, 'boxes') and hasattr(results, 'names'):\n",
    "        for box in results.boxes.xyxy:\n",
    "            object_id = int(box[-1])\n",
    "            object_name = results.names.get(object_id)\n",
    "            x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "            detected_objects.append((object_name, (x1, y1, x2, y2)))\n",
    "\n",
    "    if os.path.exists(\"faces\"):\n",
    "        shutil.rmtree(\"faces\")\n",
    "    os.makedirs(\"faces\")\n",
    "\n",
    "    for i, (object_name, (x1, y1, x2, y2)) in enumerate(detected_objects):\n",
    "        object_image = image.crop((x1, y1, x2, y2))\n",
    "        object_image.save(f\"faces/face{i}.jpg\")\n",
    "        \n",
    "    return detected_objects\n",
    "\n",
    "def faceDetection(input_image):\n",
    "    model = YOLO('best.pt')\n",
    "    results: Results = model.predict(input_image)[0]\n",
    "    return faceExtraction(input_image, model, results)\n",
    "\n",
    "def capture_and_recognize():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    cam.set(3, 640)\n",
    "    cam.set(4, 480)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image from webcam\")\n",
    "            break\n",
    "\n",
    "        frame_path = \"current_frame.jpg\"\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "\n",
    "        detected_faces = faceDetection(frame_path)\n",
    "        \n",
    "        if detected_faces:\n",
    "            names = faceRecognition(frame_path)\n",
    "            for name in names:\n",
    "                print(name)\n",
    "\n",
    "            for i, (object_name, (x1, y1, x2, y2)) in enumerate(detected_faces):\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, names[i], (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "        else:\n",
    "            print(\"No faces detected\")\n",
    "\n",
    "        cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Start real-time face recognition\n",
    "capture_and_recognize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e74d5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/anirudh/Desktop/DS_environment/F_R/current_frame.jpg: 480x640 1 face, 129.3ms\n",
      "Speed: 2.3ms preprocess, 129.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 118\u001b[0m\n\u001b[1;32m    115\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Start real-time face recognition\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m capture_and_recognize()\n",
      "Cell \u001b[0;32mIn[2], line 99\u001b[0m, in \u001b[0;36mcapture_and_recognize\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m detected_faces, face_images \u001b[38;5;241m=\u001b[39m faceDetection(frame_path)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detected_faces:\n\u001b[0;32m---> 99\u001b[0m     names \u001b[38;5;241m=\u001b[39m faceRecognition(face_images)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28mprint\u001b[39m(name)\n",
      "Cell \u001b[0;32mIn[2], line 37\u001b[0m, in \u001b[0;36mfaceRecognition\u001b[0;34m(face_images)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, face_image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(face_images):\n\u001b[1;32m     36\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m face_image\n\u001b[0;32m---> 37\u001b[0m     model \u001b[38;5;241m=\u001b[39m DeepFace\u001b[38;5;241m.\u001b[39mfind(img_path\u001b[38;5;241m=\u001b[39mimg_path, db_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase\u001b[39m\u001b[38;5;124m\"\u001b[39m, enforce_detection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFacenet512\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     40\u001b[0m         name \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/env_work/lib/python3.11/site-packages/deepface/DeepFace.py:336\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(img_path, db_path, model_name, distance_metric, enforce_detection, detector_backend, align, expand_percentage, threshold, normalization, silent, refresh_database, anti_spoofing)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind\u001b[39m(\n\u001b[1;32m    260\u001b[0m     img_path: Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m    261\u001b[0m     db_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     anti_spoofing: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[pd\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    Identify individuals in a database\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m                specified model and distance metric\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m recognition\u001b[38;5;241m.\u001b[39mfind(\n\u001b[1;32m    337\u001b[0m         img_path\u001b[38;5;241m=\u001b[39mimg_path,\n\u001b[1;32m    338\u001b[0m         db_path\u001b[38;5;241m=\u001b[39mdb_path,\n\u001b[1;32m    339\u001b[0m         model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[1;32m    340\u001b[0m         distance_metric\u001b[38;5;241m=\u001b[39mdistance_metric,\n\u001b[1;32m    341\u001b[0m         enforce_detection\u001b[38;5;241m=\u001b[39menforce_detection,\n\u001b[1;32m    342\u001b[0m         detector_backend\u001b[38;5;241m=\u001b[39mdetector_backend,\n\u001b[1;32m    343\u001b[0m         align\u001b[38;5;241m=\u001b[39malign,\n\u001b[1;32m    344\u001b[0m         expand_percentage\u001b[38;5;241m=\u001b[39mexpand_percentage,\n\u001b[1;32m    345\u001b[0m         threshold\u001b[38;5;241m=\u001b[39mthreshold,\n\u001b[1;32m    346\u001b[0m         normalization\u001b[38;5;241m=\u001b[39mnormalization,\n\u001b[1;32m    347\u001b[0m         silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[1;32m    348\u001b[0m         refresh_database\u001b[38;5;241m=\u001b[39mrefresh_database,\n\u001b[1;32m    349\u001b[0m         anti_spoofing\u001b[38;5;241m=\u001b[39manti_spoofing,\n\u001b[1;32m    350\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/env_work/lib/python3.11/site-packages/deepface/modules/recognition.py:155\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(img_path, db_path, model_name, distance_metric, enforce_detection, detector_backend, align, expand_percentage, threshold, normalization, silent, refresh_database, anti_spoofing)\u001b[0m\n\u001b[1;32m    152\u001b[0m pickled_images \u001b[38;5;241m=\u001b[39m [representation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m representation \u001b[38;5;129;01min\u001b[39;00m representations]\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Get the list of images on storage\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m storage_images \u001b[38;5;241m=\u001b[39m image_utils\u001b[38;5;241m.\u001b[39mlist_images(path\u001b[38;5;241m=\u001b[39mdb_path)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(storage_images) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m refresh_database \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo item found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_work/lib/python3.11/site-packages/deepface/commons/image_utils.py:35\u001b[0m, in \u001b[0;36mlist_images\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext_lower \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(exact_path) \u001b[38;5;28;01mas\u001b[39;00m img:  \u001b[38;5;66;03m# lazy\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     37\u001b[0m         images\u001b[38;5;241m.\u001b[39mappend(exact_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_work/lib/python3.11/site-packages/PIL/Image.py:3286\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3283\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m   3284\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 3286\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m   3288\u001b[0m preinit()\n\u001b[1;32m   3290\u001b[0m accept_warnings \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.engine.results import Results  \n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def faceRecognition(face_images):\n",
    "    unknown_faces_dir = \"./unknown/\"\n",
    "    known_faces_dir = \"./known/\"\n",
    "    extracted_names = []\n",
    "\n",
    "    if not os.path.exists(unknown_faces_dir):\n",
    "        os.makedirs(unknown_faces_dir)\n",
    "    else:\n",
    "        for file_or_folder in os.listdir(unknown_faces_dir):\n",
    "            file_or_folder_path = os.path.join(unknown_faces_dir, file_or_folder)\n",
    "            if os.path.isfile(file_or_folder_path):\n",
    "                os.remove(file_or_folder_path)\n",
    "            elif os.path.isdir(file_or_folder_path):\n",
    "                shutil.rmtree(file_or_folder_path)\n",
    "\n",
    "    if not os.path.exists(known_faces_dir):\n",
    "        os.makedirs(known_faces_dir)\n",
    "    else:\n",
    "        for file_or_folder in os.listdir(known_faces_dir):\n",
    "            file_or_folder_path = os.path.join(known_faces_dir, file_or_folder)\n",
    "            if os.path.isfile(file_or_folder_path):\n",
    "                os.remove(file_or_folder_path)\n",
    "            elif os.path.isdir(file_or_folder_path):\n",
    "                shutil.rmtree(file_or_folder_path)\n",
    "\n",
    "    for i, face_image in enumerate(face_images):\n",
    "        img_path = face_image\n",
    "        model = DeepFace.find(img_path=img_path, db_path=\"database\", enforce_detection=False, model_name=\"Facenet512\")\n",
    "\n",
    "        if model and len(model[0]['identity']) > 0:\n",
    "            name = model[0]['identity'][0].split('/')[1]\n",
    "            known_faces_path = os.path.join(known_faces_dir, f\"{i + 1}_{name}.jpg\")\n",
    "            shutil.copy(img_path, known_faces_path)\n",
    "        else:\n",
    "            name = 'unknown'\n",
    "            unknown_faces_path = os.path.join(unknown_faces_dir, f\"{i + 1}.jpg\")\n",
    "            shutil.copy(img_path, unknown_faces_path)\n",
    "            \n",
    "        extracted_names.append(name)\n",
    "    \n",
    "            \n",
    "    return extracted_names\n",
    "\n",
    "def faceExtraction(input_image, model, results):\n",
    "    image = Image.open(input_image)\n",
    "    detected_objects = []\n",
    "\n",
    "    if hasattr(results, 'boxes') and hasattr(results, 'names'):\n",
    "        for box in results.boxes.xyxy:\n",
    "            object_id = int(box[-1])\n",
    "            object_name = results.names.get(object_id)\n",
    "            x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "            detected_objects.append((object_name, (x1, y1, x2, y2)))\n",
    "\n",
    "    if os.path.exists(\"faces\"):\n",
    "        shutil.rmtree(\"faces\")\n",
    "    os.makedirs(\"faces\")\n",
    "\n",
    "    face_images = []\n",
    "    for i, (object_name, (x1, y1, x2, y2)) in enumerate(detected_objects):\n",
    "        object_image = image.crop((x1, y1, x2, y2))\n",
    "        face_path = f\"faces/face{i}.jpg\"\n",
    "        object_image.save(face_path)\n",
    "        face_images.append(face_path)\n",
    "        \n",
    "    return detected_objects, face_images\n",
    "\n",
    "def faceDetection(input_image):\n",
    "    model = YOLO('best.pt')\n",
    "    results: Results = model.predict(input_image)[0]\n",
    "    return faceExtraction(input_image, model, results)\n",
    "\n",
    "def capture_and_recognize():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    cam.set(3, 640)\n",
    "    cam.set(4, 480)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image from webcam\")\n",
    "            break\n",
    "\n",
    "        frame_path = \"current_frame.jpg\"\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "\n",
    "        detected_faces, face_images = faceDetection(frame_path)\n",
    "        \n",
    "        if detected_faces:\n",
    "            names = faceRecognition(face_images)\n",
    "            for name in names:\n",
    "                print(name)\n",
    "\n",
    "            for i, (object_name, (x1, y1, x2, y2)) in enumerate(detected_faces):\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, names[i], (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "        else:\n",
    "            print(\"No faces detected\")\n",
    "\n",
    "        cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Start real-time face recognition\n",
    "capture_and_recognize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc42bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/anirudh/Desktop/DS_environment/F_R/current_frame.jpg: 480x640 1 face, 102.7ms\n",
      "Speed: 3.7ms preprocess, 102.7ms inference, 8.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 131\u001b[0m\n\u001b[1;32m    128\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Start real-time face recognition\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m capture_and_recognize()\n",
      "Cell \u001b[0;32mIn[1], line 108\u001b[0m, in \u001b[0;36mcapture_and_recognize\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m detected_faces, face_images \u001b[38;5;241m=\u001b[39m faceDetection(frame_path)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detected_faces:\n\u001b[0;32m--> 108\u001b[0m     names, confidences \u001b[38;5;241m=\u001b[39m faceRecognition(face_images)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, confidence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(names, confidences):\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfidence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m, in \u001b[0;36mfaceRecognition\u001b[0;34m(face_images, threshold)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, face_image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(face_images):\n\u001b[1;32m     37\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m face_image\n\u001b[0;32m---> 38\u001b[0m     model \u001b[38;5;241m=\u001b[39m DeepFace\u001b[38;5;241m.\u001b[39mfind(img_path\u001b[38;5;241m=\u001b[39mimg_path, db_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase\u001b[39m\u001b[38;5;124m\"\u001b[39m, enforce_detection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFacenet512\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     41\u001b[0m         distance \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/env_work/lib/python3.11/site-packages/deepface/DeepFace.py:336\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(img_path, db_path, model_name, distance_metric, enforce_detection, detector_backend, align, expand_percentage, threshold, normalization, silent, refresh_database, anti_spoofing)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind\u001b[39m(\n\u001b[1;32m    260\u001b[0m     img_path: Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m    261\u001b[0m     db_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     anti_spoofing: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[pd\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    Identify individuals in a database\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m                specified model and distance metric\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m recognition\u001b[38;5;241m.\u001b[39mfind(\n\u001b[1;32m    337\u001b[0m         img_path\u001b[38;5;241m=\u001b[39mimg_path,\n\u001b[1;32m    338\u001b[0m         db_path\u001b[38;5;241m=\u001b[39mdb_path,\n\u001b[1;32m    339\u001b[0m         model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[1;32m    340\u001b[0m         distance_metric\u001b[38;5;241m=\u001b[39mdistance_metric,\n\u001b[1;32m    341\u001b[0m         enforce_detection\u001b[38;5;241m=\u001b[39menforce_detection,\n\u001b[1;32m    342\u001b[0m         detector_backend\u001b[38;5;241m=\u001b[39mdetector_backend,\n\u001b[1;32m    343\u001b[0m         align\u001b[38;5;241m=\u001b[39malign,\n\u001b[1;32m    344\u001b[0m         expand_percentage\u001b[38;5;241m=\u001b[39mexpand_percentage,\n\u001b[1;32m    345\u001b[0m         threshold\u001b[38;5;241m=\u001b[39mthreshold,\n\u001b[1;32m    346\u001b[0m         normalization\u001b[38;5;241m=\u001b[39mnormalization,\n\u001b[1;32m    347\u001b[0m         silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[1;32m    348\u001b[0m         refresh_database\u001b[38;5;241m=\u001b[39mrefresh_database,\n\u001b[1;32m    349\u001b[0m         anti_spoofing\u001b[38;5;241m=\u001b[39manti_spoofing,\n\u001b[1;32m    350\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/env_work/lib/python3.11/site-packages/deepface/modules/recognition.py:155\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(img_path, db_path, model_name, distance_metric, enforce_detection, detector_backend, align, expand_percentage, threshold, normalization, silent, refresh_database, anti_spoofing)\u001b[0m\n\u001b[1;32m    152\u001b[0m pickled_images \u001b[38;5;241m=\u001b[39m [representation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m representation \u001b[38;5;129;01min\u001b[39;00m representations]\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Get the list of images on storage\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m storage_images \u001b[38;5;241m=\u001b[39m image_utils\u001b[38;5;241m.\u001b[39mlist_images(path\u001b[38;5;241m=\u001b[39mdb_path)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(storage_images) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m refresh_database \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo item found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_work/lib/python3.11/site-packages/deepface/commons/image_utils.py:35\u001b[0m, in \u001b[0;36mlist_images\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext_lower \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(exact_path) \u001b[38;5;28;01mas\u001b[39;00m img:  \u001b[38;5;66;03m# lazy\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     37\u001b[0m         images\u001b[38;5;241m.\u001b[39mappend(exact_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_work/lib/python3.11/site-packages/PIL/Image.py:3286\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3283\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m   3284\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 3286\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m   3288\u001b[0m preinit()\n\u001b[1;32m   3290\u001b[0m accept_warnings \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.engine.results import Results  \n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def faceRecognition(face_images, threshold=0.4):\n",
    "    unknown_faces_dir = \"./unknown/\"\n",
    "    known_faces_dir = \"./known/\"\n",
    "    extracted_names = []\n",
    "    confidences = []\n",
    "\n",
    "    if not os.path.exists(unknown_faces_dir):\n",
    "        os.makedirs(unknown_faces_dir)\n",
    "    else:\n",
    "        for file_or_folder in os.listdir(unknown_faces_dir):\n",
    "            file_or_folder_path = os.path.join(unknown_faces_dir, file_or_folder)\n",
    "            if os.path.isfile(file_or_folder_path):\n",
    "                os.remove(file_or_folder_path)\n",
    "            elif os.path.isdir(file_or_folder_path):\n",
    "                shutil.rmtree(file_or_folder_path)\n",
    "\n",
    "    if not os.path.exists(known_faces_dir):\n",
    "        os.makedirs(known_faces_dir)\n",
    "    else:\n",
    "        for file_or_folder in os.listdir(known_faces_dir):\n",
    "            file_or_folder_path = os.path.join(known_faces_dir, file_or_folder)\n",
    "            if os.path.isfile(file_or_folder_path):\n",
    "                os.remove(file_or_folder_path)\n",
    "            elif os.path.isdir(file_or_folder_path):\n",
    "                shutil.rmtree(file_or_folder_path)\n",
    "\n",
    "    for i, face_image in enumerate(face_images):\n",
    "        img_path = face_image\n",
    "        model = DeepFace.find(img_path=img_path, db_path=\"database\", enforce_detection=False, model_name=\"Facenet512\")\n",
    "\n",
    "        if model and len(model[0]['identity']) > 0:\n",
    "            distance = model[0]['distance'][0]\n",
    "            if distance < threshold:\n",
    "                name = model[0]['identity'][0].split('/')[1]\n",
    "                known_faces_path = os.path.join(known_faces_dir, f\"{i + 1}_{name}.jpg\")\n",
    "                shutil.copy(img_path, known_faces_path)\n",
    "                extracted_names.append(name)\n",
    "                confidences.append(1 - distance)  # Convert distance to confidence (higher is better)\n",
    "            else:\n",
    "                name = 'unknown'\n",
    "                extracted_names.append(name)\n",
    "                confidences.append(None)\n",
    "        else:\n",
    "            name = 'unknown'\n",
    "            confidence = None\n",
    "            unknown_faces_path = os.path.join(unknown_faces_dir, f\"{i + 1}.jpg\")\n",
    "            shutil.copy(img_path, unknown_faces_path)\n",
    "            extracted_names.append(name)\n",
    "            confidences.append(confidence)\n",
    "            \n",
    "    return extracted_names, confidences\n",
    "\n",
    "def faceExtraction(input_image, model, results):\n",
    "    image = Image.open(input_image)\n",
    "    detected_objects = []\n",
    "\n",
    "    if hasattr(results, 'boxes') and hasattr(results, 'names'):\n",
    "        for box in results.boxes.xyxy:\n",
    "            object_id = int(box[-1])\n",
    "            object_name = results.names.get(object_id)\n",
    "            x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "            detected_objects.append((object_name, (x1, y1, x2, y2)))\n",
    "\n",
    "    if os.path.exists(\"faces\"):\n",
    "        shutil.rmtree(\"faces\")\n",
    "    os.makedirs(\"faces\")\n",
    "\n",
    "    face_images = []\n",
    "    for i, (object_name, (x1, y1, x2, y2)) in enumerate(detected_objects):\n",
    "        object_image = image.crop((x1, y1, x2, y2))\n",
    "        face_path = f\"faces/face{i}.jpg\"\n",
    "        object_image.save(face_path)\n",
    "        face_images.append(face_path)\n",
    "        \n",
    "    return detected_objects, face_images\n",
    "\n",
    "def faceDetection(input_image):\n",
    "    model = YOLO('best.pt')\n",
    "    results: Results = model.predict(input_image)[0]\n",
    "    return faceExtraction(input_image, model, results)\n",
    "\n",
    "def capture_and_recognize():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    cam.set(3, 640)\n",
    "    cam.set(4, 480)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image from webcam\")\n",
    "            break\n",
    "\n",
    "        frame_path = \"current_frame.jpg\"\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "\n",
    "        detected_faces, face_images = faceDetection(frame_path)\n",
    "        \n",
    "        if detected_faces:\n",
    "            names, confidences = faceRecognition(face_images)\n",
    "            for name, confidence in zip(names, confidences):\n",
    "                print(f\"{name}: {confidence}\")\n",
    "\n",
    "            for i, (object_name, (x1, y1, x2, y2)) in enumerate(detected_faces):\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                if confidences[i] is not None:\n",
    "                    label = f\"{names[i]} ({confidences[i]:.2f})\"\n",
    "                else:\n",
    "                    label = names[i]\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "        else:\n",
    "            print(\"No faces detected\")\n",
    "\n",
    "        cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Start real-time face recognition\n",
    "capture_and_recognize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca54ec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/anirudh/Desktop/DS_environment/F_R/current_frame.jpg: 480x640 1 face, 94.5ms\n",
      "Speed: 5.1ms preprocess, 94.5ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 237\u001b[0m\n\u001b[1;32m    235\u001b[0m     add_new_face()\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     capture_and_recognize()\n",
      "Cell \u001b[0;32mIn[1], line 180\u001b[0m, in \u001b[0;36mcapture_and_recognize\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m detected_faces, face_images \u001b[38;5;241m=\u001b[39m faceDetection(frame_path)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detected_faces:\n\u001b[0;32m--> 180\u001b[0m     names, confidences \u001b[38;5;241m=\u001b[39m faceRecognition(face_images)\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, confidence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(names, confidences):\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[0;32mIn[1], line 41\u001b[0m, in \u001b[0;36mfaceRecognition\u001b[0;34m(face_images, threshold)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, face_image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(face_images):\n\u001b[1;32m     40\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m face_image\n\u001b[0;32m---> 41\u001b[0m     model \u001b[38;5;241m=\u001b[39m DeepFace\u001b[38;5;241m.\u001b[39mfind(img_path\u001b[38;5;241m=\u001b[39mimg_path, db_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase\u001b[39m\u001b[38;5;124m\"\u001b[39m, enforce_detection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFacenet512\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     44\u001b[0m         distance \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/env_work/lib/python3.11/site-packages/deepface/DeepFace.py:336\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(img_path, db_path, model_name, distance_metric, enforce_detection, detector_backend, align, expand_percentage, threshold, normalization, silent, refresh_database, anti_spoofing)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind\u001b[39m(\n\u001b[1;32m    260\u001b[0m     img_path: Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray],\n\u001b[1;32m    261\u001b[0m     db_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     anti_spoofing: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[pd\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    Identify individuals in a database\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m                specified model and distance metric\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m recognition\u001b[38;5;241m.\u001b[39mfind(\n\u001b[1;32m    337\u001b[0m         img_path\u001b[38;5;241m=\u001b[39mimg_path,\n\u001b[1;32m    338\u001b[0m         db_path\u001b[38;5;241m=\u001b[39mdb_path,\n\u001b[1;32m    339\u001b[0m         model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[1;32m    340\u001b[0m         distance_metric\u001b[38;5;241m=\u001b[39mdistance_metric,\n\u001b[1;32m    341\u001b[0m         enforce_detection\u001b[38;5;241m=\u001b[39menforce_detection,\n\u001b[1;32m    342\u001b[0m         detector_backend\u001b[38;5;241m=\u001b[39mdetector_backend,\n\u001b[1;32m    343\u001b[0m         align\u001b[38;5;241m=\u001b[39malign,\n\u001b[1;32m    344\u001b[0m         expand_percentage\u001b[38;5;241m=\u001b[39mexpand_percentage,\n\u001b[1;32m    345\u001b[0m         threshold\u001b[38;5;241m=\u001b[39mthreshold,\n\u001b[1;32m    346\u001b[0m         normalization\u001b[38;5;241m=\u001b[39mnormalization,\n\u001b[1;32m    347\u001b[0m         silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[1;32m    348\u001b[0m         refresh_database\u001b[38;5;241m=\u001b[39mrefresh_database,\n\u001b[1;32m    349\u001b[0m         anti_spoofing\u001b[38;5;241m=\u001b[39manti_spoofing,\n\u001b[1;32m    350\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/env_work/lib/python3.11/site-packages/deepface/modules/recognition.py:155\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(img_path, db_path, model_name, distance_metric, enforce_detection, detector_backend, align, expand_percentage, threshold, normalization, silent, refresh_database, anti_spoofing)\u001b[0m\n\u001b[1;32m    152\u001b[0m pickled_images \u001b[38;5;241m=\u001b[39m [representation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m representation \u001b[38;5;129;01min\u001b[39;00m representations]\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Get the list of images on storage\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m storage_images \u001b[38;5;241m=\u001b[39m image_utils\u001b[38;5;241m.\u001b[39mlist_images(path\u001b[38;5;241m=\u001b[39mdb_path)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(storage_images) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m refresh_database \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo item found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_work/lib/python3.11/site-packages/deepface/commons/image_utils.py:35\u001b[0m, in \u001b[0;36mlist_images\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ext_lower \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(exact_path) \u001b[38;5;28;01mas\u001b[39;00m img:  \u001b[38;5;66;03m# lazy\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     37\u001b[0m         images\u001b[38;5;241m.\u001b[39mappend(exact_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/env_work/lib/python3.11/site-packages/PIL/Image.py:3286\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3283\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m   3284\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 3286\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m   3288\u001b[0m preinit()\n\u001b[1;32m   3290\u001b[0m accept_warnings \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.engine.results import Results  \n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "def faceRecognition(face_images, threshold=0.4):\n",
    "    unknown_faces_dir = \"./unknown/\"\n",
    "    known_faces_dir = \"./known/\"\n",
    "    extracted_names = []\n",
    "    confidences = []\n",
    "\n",
    "    if not os.path.exists(unknown_faces_dir):\n",
    "        os.makedirs(unknown_faces_dir)\n",
    "    else:\n",
    "        for file_or_folder in os.listdir(unknown_faces_dir):\n",
    "            file_or_folder_path = os.path.join(unknown_faces_dir, file_or_folder)\n",
    "            if os.path.isfile(file_or_folder_path):\n",
    "                os.remove(file_or_folder_path)\n",
    "            elif os.path.isdir(file_or_folder_path):\n",
    "                shutil.rmtree(file_or_folder_path)\n",
    "\n",
    "    if not os.path.exists(known_faces_dir):\n",
    "        os.makedirs(known_faces_dir)\n",
    "    else:\n",
    "        for file_or_folder in os.listdir(known_faces_dir):\n",
    "            file_or_folder_path = os.path.join(known_faces_dir, file_or_folder)\n",
    "            if os.path.isfile(file_or_folder_path):\n",
    "                os.remove(file_or_folder_path)\n",
    "            elif os.path.isdir(file_or_folder_path):\n",
    "                shutil.rmtree(file_or_folder_path)\n",
    "\n",
    "    for i, face_image in enumerate(face_images):\n",
    "        img_path = face_image\n",
    "        model = DeepFace.find(img_path=img_path, db_path=\"database\", enforce_detection=False, model_name=\"Facenet512\")\n",
    "\n",
    "        if model and len(model[0]['identity']) > 0:\n",
    "            distance = model[0]['distance'][0]\n",
    "            if distance < threshold:\n",
    "                name = model[0]['identity'][0].split('/')[1]\n",
    "                known_faces_path = os.path.join(known_faces_dir, f\"{i + 1}_{name}.jpg\")\n",
    "                shutil.copy(img_path, known_faces_path)\n",
    "                extracted_names.append(name)\n",
    "                confidences.append(1 - distance)  # Convert distance to confidence (higher is better)\n",
    "            else:\n",
    "                name = 'unknown'\n",
    "                extracted_names.append(name)\n",
    "                confidences.append(None)\n",
    "        else:\n",
    "            name = 'unknown'\n",
    "            confidence = None\n",
    "            unknown_faces_path = os.path.join(unknown_faces_dir, f\"{i + 1}.jpg\")\n",
    "            shutil.copy(img_path, unknown_faces_path)\n",
    "            extracted_names.append(name)\n",
    "            confidences.append(confidence)\n",
    "            \n",
    "    return extracted_names, confidences\n",
    "\n",
    "def faceExtraction(input_image, model, results):\n",
    "    image = Image.open(input_image)\n",
    "    detected_objects = []\n",
    "\n",
    "    if hasattr(results, 'boxes') and hasattr(results, 'names'):\n",
    "        for box in results.boxes.xyxy:\n",
    "            object_id = int(box[-1])\n",
    "            object_name = results.names.get(object_id)\n",
    "            x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "            detected_objects.append((object_name, (x1, y1, x2, y2)))\n",
    "\n",
    "    if os.path.exists(\"faces\"):\n",
    "        shutil.rmtree(\"faces\")\n",
    "    os.makedirs(\"faces\")\n",
    "\n",
    "    face_images = []\n",
    "    for i, (object_name, (x1, y1, x2, y2)) in enumerate(detected_objects):\n",
    "        object_image = image.crop((x1, y1, x2, y2))\n",
    "        face_path = f\"faces/face{i}.jpg\"\n",
    "        object_image.save(face_path)\n",
    "        face_images.append(face_path)\n",
    "        \n",
    "    return detected_objects, face_images\n",
    "\n",
    "def faceDetection(input_image):\n",
    "    model = YOLO('best.pt')\n",
    "    results: Results = model.predict(input_image)[0]\n",
    "    return faceExtraction(input_image, model, results)\n",
    "\n",
    "def save_to_csv(name, manager, group):\n",
    "    date_str = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    csv_filename = f\"{date_str}.csv\"\n",
    "    fieldnames = ['Name', 'Manager', 'Group', 'Timestamp']\n",
    "\n",
    "    file_exists = os.path.isfile(csv_filename)\n",
    "\n",
    "    with open(csv_filename, mode='a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow({\n",
    "            'Name': name,\n",
    "            'Manager': manager,\n",
    "            'Group': group,\n",
    "            'Timestamp': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        })\n",
    "\n",
    "def save_face_images(name, manager, group):\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    cam.set(3, 640)\n",
    "    cam.set(4, 480)\n",
    "\n",
    "    face_dir = os.path.join(\"database\", name)\n",
    "    if not os.path.exists(face_dir):\n",
    "        os.makedirs(face_dir)\n",
    "\n",
    "    # Save the details in a text file\n",
    "    with open(os.path.join(face_dir, 'details.txt'), 'w') as f:\n",
    "        f.write(f\"Manager: {manager}\\n\")\n",
    "        f.write(f\"Group: {group}\\n\")\n",
    "\n",
    "    count = 0\n",
    "    while count < 6:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image from webcam\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"Capture Face\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('c'):  # 'c' key to capture an image\n",
    "            face_path = os.path.join(face_dir, f\"{name}_{count + 1}.jpg\")\n",
    "            cv2.imwrite(face_path, frame)\n",
    "            count += 1\n",
    "            print(f\"Captured image {count}\")\n",
    "            time.sleep(1)  # Pause to capture a distinct image\n",
    "        elif key == 27:  # ESC key to exit\n",
    "            break\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Update the names and details file\n",
    "    update_names_and_details(name, manager, group)\n",
    "\n",
    "def update_names_and_details(name, manager, group):\n",
    "    details_file = \"names_and_details.txt\"\n",
    "\n",
    "    with open(details_file, 'a') as file:\n",
    "        file.write(f\"Name: {name}\\n\")\n",
    "        file.write(f\"Manager: {manager}\\n\")\n",
    "        file.write(f\"Group: {group}\\n\")\n",
    "        file.write(\"\\n\")  # Blank line for separation\n",
    "\n",
    "def capture_and_recognize():\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    cam.set(3, 640)\n",
    "    cam.set(4, 480)\n",
    "\n",
    "    recognized_faces = {}\n",
    "    start_times = {}\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture image from webcam\")\n",
    "            break\n",
    "\n",
    "        frame_path = \"current_frame.jpg\"\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "\n",
    "        detected_faces, face_images = faceDetection(frame_path)\n",
    "\n",
    "        if detected_faces:\n",
    "            names, confidences = faceRecognition(face_images)\n",
    "            for name, confidence in zip(names, confidences):\n",
    "                if name != 'unknown':\n",
    "                    if name not in recognized_faces:\n",
    "                        recognized_faces[name] = 0\n",
    "                        start_times[name] = time.time()\n",
    "                    else:\n",
    "                        if time.time() - start_times[name] >= 3:\n",
    "                            if recognized_faces[name] == 0:\n",
    "                                recognized_faces[name] += 1\n",
    "                                # Read the details from the text file\n",
    "                                face_dir = os.path.join(\"database\", name)\n",
    "                                with open(os.path.join(face_dir, 'details.txt'), 'r') as f:\n",
    "                                    details = f.readlines()\n",
    "                                    manager = details[0].strip().split(\": \")[1]\n",
    "                                    group = details[1].strip().split(\": \")[1]\n",
    "                                save_to_csv(name, manager, group)\n",
    "\n",
    "            # Draw bounding boxes and labels\n",
    "            for i, (object_name, (x1, y1, x2, y2)) in enumerate(detected_faces):\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                if confidences[i] is not None:\n",
    "                    label = f\"{names[i]} ({confidences[i]:.2f})\"\n",
    "                else:\n",
    "                    label = names[i]\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "        else:\n",
    "            print(\"No faces detected\")\n",
    "\n",
    "        cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "        key = cv2.waitKey(30) & 0xFF\n",
    "        if key == 27:  # ESC key to exit\n",
    "            break\n",
    "        elif key == ord('s'):  # 's' key to save the current frame\n",
    "            # Save the current frame with a timestamp\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            saved_frame_path = f\"saved_frame_{timestamp}.jpg\"\n",
    "            cv2.imwrite(saved_frame_path, frame)\n",
    "            print(f\"Frame saved as {saved_frame_path}\")\n",
    "\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Add new face to the database\n",
    "def add_new_face():\n",
    "    name = input(\"Enter the name of the person: \")\n",
    "    manager = input(\"Enter manager name: \")\n",
    "    group = input(\"Enter group: \")\n",
    "    save_face_images(name, manager, group)\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    action = input(\"Enter 'add' to add a new face or 'recognize' to start real-time recognition: \")\n",
    "    if action.lower() == 'add':\n",
    "        add_new_face()\n",
    "    else:\n",
    "        capture_and_recognize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f2148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e4095a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713fd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821efde0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.8 ('env_work')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b8ca2c7a37a74449e5a812c7f5ccc62c1166f11247e40061d33065d82a9819f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
